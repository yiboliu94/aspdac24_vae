\documentclass[journal]{IEEEtran}
% \usepackage{booktabs} % For formal tables
% \usepackage{times}
% \renewcommand{\rmdefault}{ptm}
\usepackage{multirow}
% \usepackage{array}
\usepackage{amsmath}
\usepackage{subfigure}
% \usepackage{bm}
% \usepackage{amsfonts}
\usepackage{epsfig}
\usepackage{psfrag}
% \usepackage{epstopdf}
%\usepackage{cite}
%\usepackage{url}
\newcounter{numberlistc}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{subfigure}
\usepackage{color}
\usepackage{spverbatim}
\usepackage{setspace}
\usepackage{caption}
%\usepackage{subcaption}

\newenvironment{numberlist}
    {   \setcounter{numberlistc}{0}
        \begin{list}{\arabic{numberlistc}.}
        {\usecounter{numberlistc}
        \setlength{\parsep}{0pt}
        \setlength{\topsep}{3pt}
        \setlength{\itemsep}{0pt}}
        }{ \end{list} }
\newcounter{itemlistc}
\newcounter{enumlistc}
%\renewcommand{\theromanlistc}{(\roman{romanlistc})} %for ref use
%\renewcommand{\thealphlistc}{(\alph{alphlistc})}    %for ref use
\newenvironment{itemlist}
    {   \setcounter{itemlistc}{0}
    \begin{list}{$\bullet$}
        {\usecounter{itemlistc}
        \setlength{\parsep}{0pt}
        \setlength{\topsep}{3pt}
        \setlength{\itemsep}{0pt}}
        }{ \end{list} } 

\newcommand{\rev}[1]{\textcolor{red}{#1}}

\renewcommand{\baselinestretch}{1}

% \newenvironment{packedenum}{
% \begin{enumerate}
% \setlength{\itemsep}{1pt}
% \setlength{\parskip}{0pt}
% \setlength{\parsep}{0pt}
% }{\end{enumerate}}

%\usepackage{setspace}
%\DeclareMathOperator{\rank}{rank}


%\renewcommand{\baselinestretch}{0.895}
%\IEEEoverridecommandlockouts
%\usepackage[font=small, labelfont=bf]{caption}
%\usepackage{caption}


%\renewcommand{\algorithmicrequire}{\textbf{Input:}}
%\renewcommand{\algorithmicensure}{\textbf{Output:}}
%\renewcommand{\algorithmiccomment}[1]{~~~~\textcolor{BrickRed}{// \textit{#1}}}


\begin{document}
\title{Fast Power Grid EM-Aware IR Drop Prediction and Fixing
  Accelerated by Variational AutoEncoder}

%\author{\indent Yibo Liu~\IEEEmembership{Student Member,~IEEE}, 
%Sheldon X.-D. Tan~\IEEEmembership{Senior Member,~IEEE} 
%~\thanks{\indent Yibo Liu, and Sheldon X.-D. Tan are with the Department of Electrical and 
%Computer Engineering, University of California, Riverside, Riverside, CA 92521, USA~(e-mail: stan@ece.ucr.edu).}}


\maketitle
  
\begin{abstract}
  Electromigration (EM) is the top failure mechanism for copper-interconnected current and future nanometer chip technologies. 
  Conventional analytical approaches are time costing on simulating the EM effect IR drop. 
  To size the on-chip power grid networks to ensure their EM life time during the design, another critical issue is the high computation load of the sensitivity of the fixing target with respect to the wire geometry. 
  We propose a fast full-chip power grid EM-aware IR drop prediction and fixing framework to mitigate these issues.
  We adopt the variational autoencoder (VAE)-based model to first predict the EM-aware IR drops, then leverage the auto differential feature of the deep neural networks to compute the sensitivity information very efficiently.  
  Our results show that VAE is better than recently proposed recently proposed generative adversarial network (GAN)-based model with 40$\%$ RMSE reduction. 
  Further on the power grid EM-aware IR drop fixing, we show the proposed VAE-accelerated method can lead up to 80X (at least one order of magnitude) speedup over the conventional SLP-based method on synthesized power grid benchmarks from ARM Cortex-M0 processor design.

\end{abstract}
 
\input intro.tex

\input related.tex

\input strategy.tex

\input results.tex

\section{Conclusion}
\label{sec:conclusion}
In this paper, we proposed a VAE accelerated power grid
fixing method based on a recently proposed linear programming based
optimization framework.  
we proposed to use the VAE-based model to accelerate sensitivity
computation.  Numerical results on a number of synthesized power grid
benchmarks from ARM Cortex-M0 processor designs show that the proposed
method can lead to at least one order of magnitude speedup over the
existing SLP based method. 




% \clearpage 
\bibliographystyle{IEEEtran}
\bibliography{../../bib/simulation,../../bib/modeling,../../bib/reduction,../../bib/misc,../../bib/mscad_pub,../../bib/reliability,../../bib/interconnect,../../bib/thermal_power,../../bib/machine_learning,../../bib/physical,../../bib/neural_network}
%\bibliography{bibfile}
%\input change_note.tex
% \input {bio.tex}

\end{document}
